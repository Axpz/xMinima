# GCP Dataproc 选择问题讨论

### TotoroChina (3 年，9 个月前)  
应该选择 B，你要最小化成本。  
[参考文档](https://cloud.google.com/dataproc/docs/concepts/compute/secondary-vms#preemptible_and_non-preemptible_secondary_workers)  
**点赞 68 次**

---

### J19G (3 年，5 个月前)  
同意，迁移指南也建议考虑使用预抢占的工作节点：[参考文档](https://cloud.google.com/architecture/hadoop/hadoop-gcp-migration-jobs#using_preemptible_worker_nodes)  
**点赞 4 次**

---

### ale_brd_111 (2 年，4 个月前)  
我认为是 A。    
问题没有提到要最小化成本，在 GCP 考试中，要求最小化成本的题目通常会明确提到这一点。    
另外，为了最小化成本，你需要构建容错的作业，因为工作节点是预抢占的。这也需要一些开发投入。因此，如果问题中没有提到容错和最小化成本，那么就不需要/不需要。    
文档中提到：  
> 仅在作业是容错的，或者作业优先级低到偶尔任务失败不会影响业务的情况下，使用预抢占节点。  
**点赞 2 次**

---

### Amrx (5 个月，2 周前)  
问题中明确写道：“你想最小化成本和基础设施管理工作。”  
**点赞 2 次**

---

### grejao (2 年前)  
天啊，你又来了？

---

### XDevX (3 年，9 个月前)  
你好，TotoroChina，    
我第一次读到这个问题时也有同样的想法 - 我看到的问题是，在实际业务中，我认为你会尝试混合使用预抢占实例和按需实例...这里你必须在预抢占实例和按需实例之间做选择。预抢占实例有一些缺点，所以我们需要更多的细节，理想情况下是混合的方法。这样的话，两个答案 a) 和 b) 都可能是正确的...你怎么看呢？    
谢谢！    
Cheers,    
D.  
**点赞 5 次**

---

### kopper2019 (3 年，9 个月前)  
但是你需要减少管理开销，所以选择 B。    
如果你手动创建集群并创建和维护 GCE，这不是最佳做法。  
**点赞 5 次**

---

### HenkH (2 年，5 个月前)  
B 需要每 24 小时至少创建新实例。  
**点赞 2 次**

---

### Sukon_Desknot (2 年，4 个月前)
“没有修改底层基础设施”是关键字。很可能没有使用预抢占的本地部署。  
**点赞 8 次**

---

### Yogi42 (2 年，2 个月前)  
A 作为成本节约的考虑：使用预抢占 VM 并不总是能节省成本，因为抢占可能导致作业执行时间更长，从而增加作业成本。    
这在上述链接中有提到。所以我认为答案应该是 A。  
**点赞 3 次**

---

### firecloud (3 年，8 个月前)  
是 A，主工作节点只能是标准类型，二级工作节点可以是预抢占类型。  
> 除了使用标准计算引擎 VM 作为 Dataproc 工作节点（称为“主”工作节点），Dataproc 集群还可以使用“二级”工作节点。    
有两种类型的二级工作节点：预抢占和非预抢占。所有二级工作节点必须是相同类型的，全部为预抢占。  
**点赞 35 次**

---

### Manh (3 年，7 个月前)  
同意。  
**点赞 2 次**

---

### david_tay (1 个月，2 周前)  
选择的答案：B    
它提到要节省成本，因此 B 是合理的，Hadoop 通常用于批处理作业，所以一些停机时间是可以容忍的。  
**点赞 2 次**

---

### 3a7557a (2 个月前)  
选择的答案：A    
A. 创建一个使用标准工作节点的 Dataproc 集群。    
你可以使用预抢占实例，但应保持在总工作节点的 50% 以下...可能会影响稳定性...    
缺点是临时任务失败。  
  
推荐的最佳实践：
> 开始时谨慎：从较小比例的预抢占工作节点（例如，总工作节点的不到 30%）开始。密切监控作业的表现，并根据需要进行调整。  
> 不要超过 50%：Google 通常建议将预抢占工作节点的比例保持在总工作节点的 50% 以下。这有助于保持稳定性并减少作业中断的风险。  
**点赞 1 次**

---

### plumbig11 (3 个月，1 周前)  
选择的答案：B    
Dataproc，因为他们想节省成本，预抢占是最佳选择，毫无疑问。  
**点赞 2 次**

---

### Lestrang (6 个月，1 周前)  
可能是 A  
- 主工作节点必须是标准类型。  
- 预抢占并不总是能节省成本。  
- 本地基础设施没有抢占实例。  
- 创建集群时不能选择抢占/预抢占实例，只有在配置二级节点时可以选择，它们默认就是预抢占的。  
- 它们不存储数据，只进行数据处理。  
**点赞 1 次**

---

### pcamaster (6 个月，2 周前)  
选择的答案：B    
B：这是一个多项选择题，我们需要关注问题中的关键字。    
管理开销 => 托管服务 -> Dataproc。    
成本优化 => 预抢占。  
  
对于那些说“但这也需要容错”的人：嗯，问题中没有明确提到“我们有关键作业”或“我们的数据科学团队没有考虑容错”。所以我们不应该假设需要容错。  
**点赞 2 次**

---

### afsarkhan (9 个月前)  
选择的答案：A    
我选择 A，原因是预抢占实例是不可预测的，并且没有提到工作的关键性。所以我认为答案是 A 而不是 B。  
**点赞 1 次**

---

### Gino17m (11 个月，3 周前)  
选择的答案：A    
A - 只有二级工作节点可以是预抢占实例，并且“使用预抢占 VM 并不总是能节省成本，因为抢占可能导致作业执行时间更长，从而增加作业成本”，这一点在[参考文档](https://cloud.google.com/dataproc/docs/concepts/compute/secondary-vms#preemptible_and_non-preemptible_secondary_workers)中有提到。  
**点赞 1 次**

---

### dija123 (11 个月，3 周前)  
选择的答案：B    
同意 B  
**点赞 2 次**

---

### Diwz (1 年前)  
答案是 B。    
二级工作节点的默认实例类型是预抢占 VM。  
[参考文档](https://cloud.google.com/dataproc/docs/concepts/compute/secondary-vms)  
**点赞 1 次**

---

### shashii82 (1 年，1 个月前)  
Dataproc：Dataproc 是 Google Cloud Platform 上的完全托管 Apache Spark 和 Hadoop 服务。它允许你在没有手动部署和管理 Hadoop 集群的情况下运行集群。  
  
预抢占工作节点：预抢占实例是短期、成本有效的虚拟机实例，适用于容错和批处理工作负载。由于 Hadoop 作业通常可以容忍中断，使用预抢占实例可以显著降低成本。  
  
选项 B 利用 Dataproc 的优势来管理 Hadoop 集群，无需手动部署，并利用预抢占实例来最小化成本。这非常符合最小化成本和基础设施管理工作量的目标。  
**点赞 1 次**

---

### VidhyaBupesh (1 年，1 个月前)  
使用预抢占 VM 并不总是能节省成本，因为抢占可能导致作业执行时间更长，从而增加作业成本。  
**点赞 1 次**

---

### Amrita2012 (1 年，1 个月前)  
选择的答案：A    
使用标准计算引擎 VM 作为 Dataproc 工作节点（称为“主”工作节点），预抢占实例只能用于二级工作节点，因此 A 是有效答案。  
**点赞 1 次**

---

### Pime13 (1 年，2 个月前)  
选择的答案：B    
最小化成本 -> 预抢占  
**点赞 3 次**

---

### d0094d6 (1 年，2 个月前)  
选择的答案：B    
你想最小化成本和基础设施管理工作 -> 选择 B  
**点赞 3 次**

---

### d0094d6 (1 年，2 个月前)
“你想最小化成本和基础设施管理工作” -> 选择 B  
**点赞 1 次**
