### 高赞回答与讨论汇总（问题涉及：优化批量文件传输至 Cloud Storage）

---

#### kopper2019（高赞，3 年前 2 个月）

> 嘿，大家好，2021 年 7 月 12 日发布了新的问题，共 21 个新问题在问题 #152 中。  
> 👍 13 个赞

---

#### victory108（高赞，3 年前 2 个月）

> 答案是 B：使用 gsutil 并行批量复制文件。  
> 👍 13 个赞

---

#### Gino17m（最新，5 个月 1 周前）

> 选择的答案：B  
> 支持 B。  
> 👍 1 个赞

---

#### e5019c6（9 个月 2 周前）

> 选择的答案：B  
> 我投了 A。  
> 我理解选择 B 并行上传的冲动。但请记住，这是 ETL 流程的第一步。根据我的理解，当上传一个文件时，会触发一个提取过程，然后是加载。如果多个文件同时完成上传，提取和加载过程也会并行触发，如果系统没有做好准备，可能会导致错误。  
> 不过，现在我重新阅读问题，发现它并没有说明有自动化，所以 B 在这种情况下可能是可以的……  
> 👍 1 个赞

---

#### odacir（10 个月 3 周前）

> 选择的答案：B  
> 我改变主意了，是 B！  
> 👍 1 个赞

---

#### odacir（10 个月 3 周前）

> 选择的答案：C  
> 为什么不是 C？并行批量复制文件确实不错，但这是一次性的或者偶尔使用的情况，会需要人工干预……所以在这种情况下我会选择 C。也许更好的解决方案是使用事件驱动通信，比如 Kafka 或 Pub/Sub，但在这个场景中更像是调度型，ETL 工具看起来是合适的选择。  
> 👍 1 个赞

---

#### Gino17m（5 个月 1 周前）

> 我最初也选择了 C，但问题是关于“需要优化批量文件传输至 Cloud Storage”，而不是关于 ETL。  
> 👍 1 个赞

---

#### surajkrishnamurthy（1 年 9 个月前）

> 选择的答案：B  
> B 是正确答案。并行批量复制节省时间，是一个高效的选项（使用 -m 参数）。  
> 👍 1 个赞

---

#### megumin（1 年 11 个月前）

> 选择的答案：B  
> B 没问题。  
> 👍 2 个赞

---

#### AHUI（1 年 12 个月前）

> C 是不正确的，gsutil 不负责提取文件。  
> 👍 1 个赞

---

#### AzureDP900（1 年 12 个月前）

> B 很好。  
> 👍 2 个赞

---

#### Mikado211（2 年 2 个月前）

> 选择的答案：B  
> 当 GCP PCA 认证考试变成了英文阅读理解测试而不是计算机科学测试时 ^^'  
> 正确答案是 B！  
> 👍 5 个赞

---

#### DrishaS4（2 年 2 个月前）

> 选择的答案：B  
> 使用 gsutil 并行批量复制文件。  
> 👍 1 个赞

---

#### Nirca（2 年 2 个月前）

> 选择的答案：B  
> 是 B！  
> 👍 1 个赞

---

#### muky31dec（2 年 8 个月前）

> 我在考试中选择了 B。  
> 👍 2 个赞

---

#### joe2211（2 年 10 个月前）

> 选择的答案：B  
> 投票支持 B。  
> 👍 2 个赞

---

#### MaxNRG（2 年 11 个月前）

> 正确答案：B  
> https://cloud.google.com/storage/docs/gsutil/commands/cp  
> 如果你有大量文件要传输，可以使用顶层选项 -m 执行并行多线程/多进程复制（参见 gsutil help options）：  
> gsutil -m cp -r dir gs://my-bucket  
> 👍 5 个赞

---

#### riley5（3 年 3 个月前）

> 答案是 B。  
> 👍 5 个赞
