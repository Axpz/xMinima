### 用户反馈

#### cetanx - 高票

**3年前，9个月前**
  
我从不同的角度来看待这个问题；  
A、B 说“移动所有数据”，但分析将尝试揭示里程超过 100K 英里的车辆，因此没有必要传输低于 100K 英里里程的车辆数据。  
因此，传输所有数据只是浪费时间和金钱。
  
有一点是肯定的。如果我们在不同大陆之间移动/复制数据，将会花费金钱，因此在复制到另一区域/大陆之前压缩数据是有意义的。  
预处理也有意义，因为我们可能想要先处理更小的数据块（记住 100K 英里的里程）。  
那么目标存储桶类型是：多区域存储还是标准存储？多区域适用于高可用性和低延迟，虽然成本稍高，但问题没有要求这些特性。  
因此，我认为标准存储选项适合，因为较低的成本总是更好。
  
所以我的答案是 D

**点赞数**: 66

#### DiegoQ

**3年前，6个月前**
  
我完全同意你的观点，我认为让人困惑的是“运行原始数据”，但预处理不一定意味着必须转换原始数据，它也可以仅仅是选择你需要的数据（如你所说：里程少于 100K 的车辆）

**点赞数**: 2

#### mrhege

**3年前**
  
你也需要来自未损坏机器的数据进行标记。

**点赞数**: 1

#### stfnz

**10个月，4周前**
  
是的，你仍然会对 100K+ 里程感兴趣，无论是否损坏。

**点赞数**: 1

#### JoeShmoe - 高票

**4年前，4个月前**
  
D 是最具成本效益的，而 DataProc 是区域性的。

**点赞数**: 32

#### nitinz

**3年前，1个月前**
  
是 D。

**点赞数**: 1

#### Rafaa

**3年前，10个月前**
  
等等，大家，你不需要“预处理”数据。这就排除了 C 和 D。

**点赞数**: 2

#### guid1984

**3年前，1个月前**
  
为什么不呢？它是原始数据，因此可以进行预处理以优化。

**点赞数**: 2

#### passnow

**4年前，3个月前**
  
Dataproc 也可以使用全球端点。

**点赞数**: 1

#### tartar

**3年前，8个月前**
  
D 可以。

**点赞数**: 11

#### passnow

**4年前，3个月前**
  
老实说，如果我们读得清楚这个问题并考虑到成本，D 会是更好的选择。

**点赞数**: 2

#### vindahake

**4年前**
  
我认为在区域内运行额外的计算将比数据传输费用更贵，并且需要集中处理。

**点赞数**: 4

#### msahdra - 最新

**4个月，1周前**

**选定答案**: C    
虽然区域性预处理可以高效，但将数据压缩后再移动到区域性存储桶，实际上会违背多区域存储桶的目的。它增加了不必要的数据传输成本，并降低了预处理数据的全球分析可用性。

**点赞数**: 2

#### thewalker

**5个月前**
  
D    
参考 [Google Cloud 存储位置考虑](https://cloud.google.com/storage/docs/locations#considerations)

**点赞数**: 2

#### Jeena345

**1年，2个月前**

**选定答案**: D    
D 应该没问题。

**点赞数**: 1

#### omermahgoub

**1年，3个月前**

**选定答案**: C    
为了以最具成本效益的方式运行 TerramEarth 车辆的所有原始遥测数据报告，最好在每个区域启动集群进行预处理和压缩原始数据。这将允许你就地处理数据，从而最小化需要跨区域传输的数据量。数据预处理和压缩后，你可以将其移动到多区域存储桶中，并使用 Dataproc 集群完成任务。

**点赞数**: 2

#### omermahgoub

**1年，3个月前**
  
D，将数据移动到区域性存储桶并使用 Cloud Dataproc 集群完成任务，与将数据移动到多区域存储桶相比，并不具备成本效益，因为它不会利用多区域存储桶存储数据的较低成本。

**点赞数**: 1

#### megumin

**1年，5个月前**

**选定答案**: D    
可以选 D。

**点赞数**: 1

#### Mahmoud_E

**1年，5个月前**

**选定答案**: D    
D 看起来更好。

**点赞数**: 1

#### AMohanty

**1年，8个月前**
  
如果你的存储数据是区域性的，那么多区域 Dataproc 有什么用？

**点赞数**: 2

#### AzureDP900

**1年，9个月前**
  
D 没问题，C 中提到的多区域没有必要。

**点赞数**: 2

#### vincy2202

**2年，4个月前**

**选定答案**: D    
D 是正确答案。需要区域性存储桶，因为多区域存储桶会增加将数据传输到集中位置的额外成本。

**点赞数**: 2

#### vincy2202

**2年，4个月前**
  
D 看起来是正确答案。

**点赞数**: 1

#### joe2211

**2年，4个月前**

**选定答案**: D    
选 D。

**点赞数**: 2

#### MaxNRG

**2年，5个月前**
  
D – 在每个区域启动集群来预处理和压缩原始数据，然后将数据移动到区域存储桶并使用 Cloud Dataproc 集群。    
出口流量费用最为重要。区域内是免费的，因此将所有数据移到一个区域进行处理/性能优化（来自所有大陆）是有意义的。跨区域的成本是每 GB 0.01 美元，跨大陆是每 GB 0.12 美元。    
如果只考虑选项 B（将所有原始数据移动到一个区域），那么每月流量费用将是：    
900 TB（每天 2000 万个单元）* 30 天 * 0.12 美元 = 324 万美元（仅数据传输费用）。    
因此，预处理/压缩每个区域的数据，再将所有数据移动到一个区域进行最终分析是有意义的。这样可以节省高达 10-100 倍的出口成本。另一个重要方面是处理时间——在所有区域并行运行它可以加速整体分析过程。更快的结果——更快的现场改进。    
看看这个关于 GCP 中价格优化的有趣视频（前 11.5 分钟讲的是存储/网络）  
[视频链接](https://cloud.google.com/storage/docs/locations#considerations)

**点赞数**: 6

#### victory108

**2年，9个月前**
  
D。    
在每个区域启动集群来预处理和压缩原始数据，然后将数据移动到区域存储桶并使用 Cloud Dataproc 集群完成任务。

**点赞数**: 1

#### MamthaSJ

**2年，9个月前**
  
答案是 D。

**点赞数**: 3

#### Yogikant

**2年，10个月前**
  
答案 D：
  
将数据从一个区域移动到另一个区域将产生网络出口费用。通过压缩数据然后移动可以减少这些费用。虽然在每个区域运行 Dataproc 进行预处理会产生额外费用，但它也会减少在所有预处理数据上运行 Dataproc 作业的成本，从而抵消在区域级别的 Dataproc 集群的额外费用。

**点赞数**: 1
